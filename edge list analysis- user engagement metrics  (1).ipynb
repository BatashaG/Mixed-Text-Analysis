{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ce3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('edge_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45197cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group the data by the 'Year' column\n",
    "grouped_data = df.groupby('Year')\n",
    "\n",
    "# Create a new figure for the plot with specified dimensions\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the data using a line plot with markers\n",
    "# 'grouped_data['Year'].count()' calculates the number of posts for each year\n",
    "plt.plot(grouped_data['Year'].count(), marker='o')\n",
    "\n",
    "# Set labels for the x-axis and y-axis\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Posts')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Number of Reddit Posts Over Time')\n",
    "\n",
    "# Display grid lines on the plot\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80abf45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group the data by the 'Year' column\n",
    "grouped_data = df.groupby('Year')\n",
    "\n",
    "# Create a new figure for the plot with specified dimensions\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the average 'Upvote Count' over time with circular markers\n",
    "plt.plot(grouped_data['Upvote Count'].mean(), marker='o', label='Average Upvote Count')\n",
    "\n",
    "# Plot the average 'Comment Count' over time with circular markers\n",
    "plt.plot(grouped_data['Comment Count'].mean(), marker='o', label='Average Comment Count')\n",
    "\n",
    "# Plot the average 'Upvote Ratio' over time with circular markers\n",
    "plt.plot(grouped_data['Upvote Ratio'].mean(), marker='o', label='Average Upvote Ratio')\n",
    "\n",
    "# Set labels for the x-axis and y-axis\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Metrics')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Engagement Metrics Over Time')\n",
    "\n",
    "# Display a legend to differentiate between the plotted metrics\n",
    "plt.legend()\n",
    "\n",
    "# Display grid lines on the plot\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53faade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the relationship between 'Type', 'Upvote Count', and 'Comment Count'\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Box plot for 'Upvote Count' by 'Type'\n",
    "sns.boxplot(x='Type', y='Upvote Count', data=df)\n",
    "plt.title('Box Plot of Upvote Count by Type')\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Upvote Count')\n",
    "plt.show()\n",
    "\n",
    "# Box plot for 'Comment Count' by 'Type'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Type', y='Comment Count', data=df)\n",
    "plt.title('Box Plot of Comment Count by Type')\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Comment Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc31529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of 'Upvote Count' and 'Comment Count' colored by 'Type'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='Upvote Count', y='Comment Count', hue='Type', palette='Set1', s=100)\n",
    "plt.title('Scatter Plot of Upvote Count vs. Comment Count')\n",
    "plt.xlabel('Upvote Count')\n",
    "plt.ylabel('Comment Count')\n",
    "plt.legend(title='Type', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c740516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by the 'Year' column\n",
    "grouped_data = df.groupby('Year')\n",
    "\n",
    "# Create a new figure for the plot with specified dimensions\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the average sentiment polarity of posts over time with circular markers\n",
    "plt.plot(grouped_data['Sentiment'].mean(), marker='o')\n",
    "\n",
    "# Set labels for the x-axis and y-axis\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Sentiment Polarity')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Sentiment of Reddit Posts Time')\n",
    "\n",
    "# Display grid lines on the plot\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c694d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Post Flair'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ffb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Categorize Posts based on Flairs\n",
    "# Create a new column 'Category' based on keywords in 'Post Flair'\n",
    "def categorize_flair(flair):\n",
    "    if isinstance(flair, str):\n",
    "        flair = flair.lower()\n",
    "        if 'environment' in flair:\n",
    "            return 'Environmental'\n",
    "        elif 'energy' in flair:\n",
    "            return 'Energy'\n",
    "        elif 'technology' in flair:\n",
    "            return 'Technological'\n",
    "    return 'Other'\n",
    "\n",
    "df['Category'] = df['Post Flair'].apply(categorize_flair)\n",
    "\n",
    "# Step 2: Compare Engagement Metrics across Flairs\n",
    "engagement_metrics = df.groupby('Category').agg({\n",
    "    'Upvote Count': 'mean',\n",
    "    'Comment Count': 'mean',\n",
    "    'Upvote Ratio': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(engagement_metrics)\n",
    "\n",
    "# Step 3: Topic Modeling within each Flair Category\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Perform topic modeling for each flair category\n",
    "for category in df['Category'].unique():\n",
    "    corpus = df[df['Category'] == category]['Post Title'].tolist()\n",
    "\n",
    "    # TF-IDF vectorization\n",
    "    vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # LDA Topic Modeling\n",
    "    lda_model = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "    lda_model.fit(tfidf_matrix)\n",
    "\n",
    "    # Get dominant topics and probabilities\n",
    "    topics = []\n",
    "    for idx, topic in enumerate(lda_model.components_):\n",
    "        keywords = [vectorizer.get_feature_names()[i] for i in topic.argsort()[-10:]]\n",
    "        topics.append(', '.join(keywords))\n",
    "\n",
    "    print(f\"Topics for {category} category:\")\n",
    "    for idx, topic in enumerate(topics):\n",
    "        print(f\"Topic {idx + 1}: {topic}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57916c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries for plotting and visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a new figure for the plot with specified dimensions\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use Seaborn's barplot function to create a bar chart\n",
    "# Set 'Category' as the x-axis variable and 'Upvote Count' as the y-axis variable\n",
    "# Use the 'engagement_metrics' DataFrame as the data source\n",
    "sns.barplot(x='Category', y='Upvote Count', data=engagement_metrics)\n",
    "\n",
    "# Set label for the x-axis\n",
    "plt.xlabel('Category')\n",
    "\n",
    "# Set label for the y-axis\n",
    "plt.ylabel('Average Upvote Count')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Comparison of Average Upvote Count across Categories')\n",
    "\n",
    "# Rotate the x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display grid lines on the plot\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7722542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perform topic modeling for each flair category\n",
    "for category in df['Category'].unique():\n",
    "    corpus = df[df['Category'] == category]['Post Title'].tolist()\n",
    "\n",
    "    # TF-IDF vectorization\n",
    "    vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # LDA Topic Modeling\n",
    "    lda_model = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "    lda_model.fit(tfidf_matrix)\n",
    "\n",
    "    # Get dominant topics and probabilities\n",
    "    topics = []\n",
    "    for idx, topic in enumerate(lda_model.components_):\n",
    "        keywords = [vectorizer.get_feature_names()[i] for i in topic.argsort()[-10:]]\n",
    "        topics.append(', '.join(keywords))\n",
    "\n",
    "    print(f\"Topics for {category} category:\")\n",
    "    for idx, topic in enumerate(topics):\n",
    "        print(f\"Topic {idx + 1}: {topic}\")\n",
    "\n",
    "        # Generate word cloud for the topic\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(topic)\n",
    "\n",
    "        # Plot the word cloud\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Word Cloud for Topic {idx + 1} in {category} Category\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23470aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty matrix to store the topic-word frequency data\n",
    "topic_word_matrix = []\n",
    "\n",
    "# Iterate through each topic in the 'topics' list\n",
    "for topic in topics:\n",
    "    # Split the topic into individual words\n",
    "    words = topic.split(', ')\n",
    "    \n",
    "    # Count the frequency of each word in the corpus and append to the matrix\n",
    "    topic_word_matrix.append([corpus.count(word) for word in words])\n",
    "\n",
    "# Create a DataFrame from the topic-word matrix and use words as column names\n",
    "df_topic_word = pd.DataFrame(topic_word_matrix, columns=words)\n",
    "\n",
    "# Create a new figure for the heatmap with specified dimensions\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use Seaborn's heatmap function to create a heatmap\n",
    "# Use the 'df_topic_word' DataFrame as the data source\n",
    "# Use the 'YlGnBu' color map, display annotations, and format annotations as integers\n",
    "sns.heatmap(df_topic_word, cmap='YlGnBu', annot=True, fmt='d')\n",
    "\n",
    "# Set the title of the heatmap\n",
    "plt.title(\"Topic-Word Heatmap\")\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a9bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the count of each topic in the corpus and store in a list\n",
    "topic_counts = [corpus.count(topic) for topic in topics]\n",
    "\n",
    "# Calculate the total number of posts in the corpus\n",
    "total_posts = len(corpus)\n",
    "\n",
    "# Create a new figure for the pie chart with specified dimensions\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use the plt.pie function to create a pie chart\n",
    "# Set the 'x' parameter to the list of topic counts, 'labels' to the list of topics, and 'autopct' to format percentage display\n",
    "plt.pie(topic_counts, labels=topics, autopct='%1.1f%%')\n",
    "\n",
    "# Set the title of the pie chart\n",
    "plt.title(\"Topic Distribution\")\n",
    "\n",
    "# Display the pie chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85729a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the NetworkX library\n",
    "import networkx as nx\n",
    "\n",
    "# Create an empty graph using NetworkX\n",
    "G = nx.Graph()\n",
    "\n",
    "# Loop through each topic in the list of topics\n",
    "for idx, topic in enumerate(topics):\n",
    "    # Split the topic string into individual words\n",
    "    words = topic.split(', ')\n",
    "    \n",
    "    # Loop through each word in the topic\n",
    "    for word1 in words:\n",
    "        # Loop through each word again\n",
    "        for word2 in words:\n",
    "            # Ensure that the two words are not the same\n",
    "            if word1 != word2:\n",
    "                # Add an edge between the two words in the graph\n",
    "                G.add_edge(word1, word2)\n",
    "\n",
    "# Create a new figure for the network visualization with specified dimensions\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use the nx.draw function to draw the network graph\n",
    "# Set 'with_labels' to True to display labels on nodes, 'node_size' to set the size of nodes,\n",
    "# 'node_color' to set the color of nodes, 'font_size' to set the size of node labels,\n",
    "# and 'font_weight' to set the weight of node labels\n",
    "nx.draw(G, with_labels=True, node_size=2000, node_color='skyblue', font_size=10, font_weight='bold')\n",
    "\n",
    "# Set the title of the network visualization\n",
    "plt.title(\"Word Network for Topics\")\n",
    "\n",
    "# Display the network visualization\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot for Upvote Count vs. Sentiment\n",
    "plt.scatter(df['Sentiment'], df['Upvote Count'])\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Upvote Count')\n",
    "plt.title('Upvote Count vs. Sentiment')\n",
    "plt.show()\n",
    "\n",
    "# Bar plot for average Comment Count across different sentiment categories\n",
    "sentiment_groups = df.groupby('Sentiment')['Comment Count'].mean().reset_index()\n",
    "plt.bar(sentiment_groups['Sentiment'], sentiment_groups['Comment Count'])\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Average Comment Count')\n",
    "plt.title('Average Comment Count for Different Sentiment Categories')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e28d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "corpus = df['Post Title'].tolist()\n",
    "\n",
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# LDA Topic Modeling\n",
    "lda_model = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda_model.fit(tfidf_matrix)\n",
    "\n",
    "# Get dominant topics and probabilities\n",
    "topics = []\n",
    "for idx, topic in enumerate(lda_model.components_):\n",
    "    keywords = [vectorizer.get_feature_names()[i] for i in topic.argsort()[-10:]]\n",
    "    topics.append(', '.join(keywords))\n",
    "\n",
    "# Add the dominant topic as a new column to the DataFrame\n",
    "df['Dominant Topic'] = [topics[i] for i in lda_model.transform(tfidf_matrix).argmax(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Analyze Distribution across Years\n",
    "topics_by_year = df.groupby('Year')['Dominant Topic'].value_counts().unstack(fill_value=0)\n",
    "print(topics_by_year)\n",
    "\n",
    "# Option 2: Analyze Distribution across Post Flairs\n",
    "topics_by_flair = df.groupby('Post Flair')['Dominant Topic'].value_counts().unstack(fill_value=0)\n",
    "print(topics_by_flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b3074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Option 1: Visualize Distribution across Years\n",
    "topics_by_year.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Posts')\n",
    "plt.title('Distribution of Topics across Years')\n",
    "plt.legend(title='Dominant Topic', loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Option 2: Visualize Distribution across Post Flairs\n",
    "topics_by_flair.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "plt.xlabel('Post Flair')\n",
    "plt.ylabel('Number of Posts')\n",
    "plt.title('Distribution of Topics across Post Flairs')\n",
    "plt.legend(title='Dominant Topic', loc='upper right')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584ebcdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the WordCloud library\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Loop through each unique dominant topic in the DataFrame\n",
    "for topic in df['Dominant Topic'].unique():\n",
    "    # Concatenate all post titles associated with the current topic\n",
    "    text = \" \".join(df[df['Dominant Topic'] == topic]['Post Title'])\n",
    "    \n",
    "    # Generate a WordCloud using the concatenated text\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    \n",
    "    # Create a new figure for the WordCloud visualization with specified dimensions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Display the WordCloud image using imshow\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    \n",
    "    # Turn off axis labels\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    # Set the title of the WordCloud visualization\n",
    "    plt.title(f\"Word Cloud for Topic: {topic}\")\n",
    "    \n",
    "    # Display the WordCloud visualization\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe82cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Option 1: Heatmap for Distribution across Years\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(topics_by_year, cmap='YlGnBu', annot=True, fmt='d')\n",
    "plt.xlabel('Dominant Topic')\n",
    "plt.ylabel('Year')\n",
    "plt.title('Topic Distribution Heatmap across Years')\n",
    "plt.show()\n",
    "\n",
    "# Option 2: Heatmap for Distribution across Post Flairs\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(topics_by_flair, cmap='YlGnBu', annot=True, fmt='d', cbar_kws={'label': 'Number of Posts'})\n",
    "plt.xlabel('Dominant Topic')\n",
    "plt.ylabel('Post Flair')\n",
    "plt.title('Topic Distribution Heatmap across Post Flairs')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b2a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by post author and calculate the sum of upvotes and comments\n",
    "user_engagement = df.groupby('Post Author').agg({\n",
    "    'Upvote Count': 'sum',\n",
    "    'Comment Count': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate total engagement metric (e.g., sum of upvotes and comments)\n",
    "user_engagement['Total Engagement'] = user_engagement['Upvote Count'] + user_engagement['Comment Count']\n",
    "\n",
    "# Sort the users based on total engagement to find the most active ones\n",
    "most_active_users = user_engagement.sort_values(by='Total Engagement', ascending=False).head(10)\n",
    "print(most_active_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab400986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart to visualize the number of posts made by each user\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(most_active_users['Post Author'], most_active_users['Total Engagement'])\n",
    "plt.xlabel('User')\n",
    "plt.ylabel('Total Engagement')\n",
    "plt.title('Top 10 Most Active Users')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation between engagement metrics and sentiment\n",
    "engagement_sentiment_corr = df[['Upvote Count', 'Comment Count', 'Sentiment']].corr()\n",
    "\n",
    "# Create a heatmap to visualize the correlation\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(engagement_sentiment_corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation between User Engagement Metrics and Sentiment')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract posts made by the most active users\n",
    "most_active_user_posts = df[df['Post Author'].isin(most_active_users['Post Author'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba16014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Prepare the corpus for topic modeling\n",
    "corpus = most_active_user_posts['Post Title'].tolist()\n",
    "\n",
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "\n",
    "# LDA Topic Modeling\n",
    "lda_model = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "lda_model.fit(tfidf_matrix)\n",
    "\n",
    "\n",
    "# Get dominant topics and probabilities\n",
    "topics = []\n",
    "for idx, topic in enumerate(lda_model.components_):\n",
    "    keywords = [vectorizer.get_feature_names()[i] for i in topic.argsort()[-10:]]\n",
    "    topics.append(', '.join(keywords))\n",
    "\n",
    "# Add the topics to the most_active_users DataFrame\n",
    "most_active_users['Dominant Topics'] = topics\n",
    "print(most_active_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f53be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart to visualize the dominant topics for each user\n",
    "plt.figure(figsize=(12, 6))\n",
    "for index, row in most_active_users.iterrows():\n",
    "    topics = row['Dominant Topics']\n",
    "    plt.barh(row['Post Author'], row['Total Engagement'], label=topics)\n",
    "\n",
    "plt.xlabel('Total Engagement')\n",
    "plt.ylabel('User')\n",
    "plt.title('Top 10 Most Active Users and their Dominant Topics')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e905ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot to compare average upvote counts across categories\n",
    "sns.barplot(x='Category', y='Upvote Count', data=df)\n",
    "plt.title('Average Upvote Count across Categories')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Average Upvote Count')\n",
    "plt.show()\n",
    "\n",
    "# Group the data by year and count the number of posts in each year\n",
    "posts_by_year = df.groupby('Year')['Post ID'].count().reset_index()\n",
    "posts_by_year = posts_by_year.rename(columns={'Post ID': 'Post Count'})\n",
    "\n",
    "# Create a line plot to visualize the number of posts over time\n",
    "sns.lineplot(x='Year', y='Post Count', data=posts_by_year)\n",
    "plt.title('Number of Posts over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Posts')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8448b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap to visualize correlation between upvote count and comment count\n",
    "correlation_matrix = df[['Upvote Count', 'Comment Count']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap: Upvote Count vs. Comment Count')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
